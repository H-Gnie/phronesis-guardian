import streamlit as st
import google.generativeai as genai
import time

# ---------------------------------------------------------
# [ì„¤ì •] ì‹œìŠ¤í…œ UI êµ¬ì„± (ì—¬ê¸°ê°€ ê°„íŒì…ë‹ˆë‹¤)
# ---------------------------------------------------------
st.set_page_config(
    page_title="Phronesis Guardian System",
    page_icon="ğŸ›¡ï¸",
    layout="wide"  # í™”ë©´ì„ ë„“ê²Œ ì¨ì„œ ëŒ€ì‹œë³´ë“œ ëŠë‚Œ ë‚˜ê²Œ ë³€ê²½
)

# í—¤ë” ë””ìì¸
st.title("ğŸ›¡ï¸ Phronesis Guardian: í”„ë¦¬ ì—ì´ì „íŠ¸ ì¤‘ì¬ ì‹œìŠ¤í…œ")
st.markdown("""
**System Status:** âœ… Online | **Role:** Mediator & Value Extractor
- **Module 1:** ê°€ì¹˜ ë°œêµ´ (Extractor)
- **Module 2:** ë³´ì•ˆ ë° ë§¤ì¹­ (Security)
- **Module 3:** ì†Œí†µ ì¤‘ì¬ (Mediator)
- **Module 4:** ë³´ìƒ í‰ê°€ (Reward)
""")
st.divider() # êµ¬ë¶„ì„  ì¶”ê°€

# ---------------------------------------------------------
# [ì—°ê²°] ë‡Œ(Brain) ì—°ê²°
# ---------------------------------------------------------
API_KEY = "AIzaSyDlTX-JaNtI4W8GngNHSl2VkT6G7GUG0x0"
genai.configure(api_key=API_KEY)

try:
    with open("system_prompt.md", "r", encoding="utf-8") as f:
        system_instruction = f.read()
except FileNotFoundError:
    st.error("âŒCRITICAL ERROR: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(system_prompt.md)ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

model = genai.GenerativeModel(
    model_name="gemini-flash-latest",
    system_instruction=system_instruction
)

# ---------------------------------------------------------
# [ì¸í„°í˜ì´ìŠ¤] ëŒ€í™”ì°½ êµ¬í˜„
# ---------------------------------------------------------
if "messages" not in st.session_state:
    # ì‹œìŠ¤í…œì´ ë¨¼ì € ë§ì„ ê±¸ë„ë¡ ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
    st.session_state.messages = [
        {"role": "assistant", "content": "ì‹œìŠ¤í…œì´ ê°€ë™ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ê²½ë ¥ì´ë‚˜ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì…ë ¥í•´ì£¼ì‹œë©´, 'ê°€ì¹˜ ë°œêµ´ ëª¨ë“ˆ'ì´ ì‘ë™í•©ë‹ˆë‹¤."}
    ]

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ì°½ (ë¬¸êµ¬ ë³€ê²½ë¨)
if prompt := st.chat_input("ê²½í—˜, ìê²©ì¦, í˜¹ì€ í”„ë¡œì íŠ¸ ì´ë ¥ì„ ì…ë ¥í•˜ì—¬ ê²€ì¦ì„ ì‹œì‘í•˜ì‹­ì‹œì˜¤."):
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # AI ì‘ë‹µ ì²˜ë¦¬
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("ğŸ”„ *Analyzing context... (ê°€ì¹˜ ë° ì§„ìœ„ ì—¬ë¶€ ë¶„ì„ ì¤‘)*")
        
        try:
            # ì•½ê°„ì˜ ë”œë ˆì´ë¥¼ ì¤˜ì„œ ì§„ì§œ ë¶„ì„í•˜ëŠ” ëŠë‚Œ ì—°ì¶œ
            time.sleep(0.7) 
            
            history = []
            for msg in st.session_state.messages:
                role = "user" if msg["role"] == "user" else "model"
                if msg["content"] != prompt:
                    # ì‹œìŠ¤í…œ ì²« ì¸ì‚¬ëŠ” íˆìŠ¤í† ë¦¬ì— ë„£ì§€ ì•ŠìŒ (ì˜¤ë¥˜ ë°©ì§€)
                    if msg["content"] != "ì‹œìŠ¤í…œì´ ê°€ë™ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ê²½ë ¥ì´ë‚˜ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì…ë ¥í•´ì£¼ì‹œë©´, 'ê°€ì¹˜ ë°œêµ´ ëª¨ë“ˆ'ì´ ì‘ë™í•©ë‹ˆë‹¤.":
                         history.append({"role": role, "parts": [msg["content"]]})
            
            chat = model.start_chat(history=history)
            response = chat.send_message(prompt)
            
            message_placeholder.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            
        except Exception as e:
            message_placeholder.error(f"âš ï¸ System Error: {e}")